{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#from preamble import *\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = \"gray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Learning and Preprocessing\n",
    "\n",
    "### 3.1 Types of unsupervised learning\n",
    "\n",
    "- 비지도 변환 (Unsupervised Transform)\n",
    "  - 차원 축소 (Dimensionality Reduction)\n",
    "- 군집 (Clustering)\n",
    "\n",
    "### 3.2 Challenges in unsupervised learning\n",
    "\n",
    "- 비지도 학습은 데이터 과학자가 데이터를 더 잘 이해하고 싶을 때 탐색적 분석 (EDA) 단계에 많이 활용\n",
    "- 지도 학습의 전처리 단뎨에서도 많이 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preprocessing and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Applying Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n",
      "\n",
      "(143, 30)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스케일링을 수행할 scaler에게 fit 함수를 호출함. 이때 훈련 데이터만 넘겨줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제로 훈련 데이터의 스케일을 조정하려면 scaler의 transform 메소드를 호출함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed shape: (426, 30)\n",
      "per-feature minimum before scaling:\n",
      " [  6.98100000e+00   9.71000000e+00   4.37900000e+01   1.43500000e+02\n",
      "   5.26300000e-02   1.93800000e-02   0.00000000e+00   0.00000000e+00\n",
      "   1.06000000e-01   5.02400000e-02   1.15300000e-01   3.60200000e-01\n",
      "   7.57000000e-01   6.80200000e+00   1.71300000e-03   2.25200000e-03\n",
      "   0.00000000e+00   0.00000000e+00   9.53900000e-03   8.94800000e-04\n",
      "   7.93000000e+00   1.20200000e+01   5.04100000e+01   1.85200000e+02\n",
      "   7.11700000e-02   2.72900000e-02   0.00000000e+00   0.00000000e+00\n",
      "   1.56600000e-01   5.52100000e-02]\n",
      "per-feature maximum before scaling:\n",
      " [  2.81100000e+01   3.92800000e+01   1.88500000e+02   2.50100000e+03\n",
      "   1.63400000e-01   2.86700000e-01   4.26800000e-01   2.01200000e-01\n",
      "   3.04000000e-01   9.57500000e-02   2.87300000e+00   4.88500000e+00\n",
      "   2.19800000e+01   5.42200000e+02   3.11300000e-02   1.35400000e-01\n",
      "   3.96000000e-01   5.27900000e-02   6.14600000e-02   2.98400000e-02\n",
      "   3.60400000e+01   4.95400000e+01   2.51200000e+02   4.25400000e+03\n",
      "   2.22600000e-01   9.37900000e-01   1.17000000e+00   2.91000000e-01\n",
      "   5.77400000e-01   1.48600000e-01]\n",
      "per-feature minimum after scaling:\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "per-feature maximum after scaling:\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# transform data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# print dataset properties before and after scaling\n",
    "print(\"transformed shape: {}\".format(X_train_scaled.shape))\n",
    "\n",
    "# axis=0 --> 426개의 데이터들에 대해 동일한 Colume에 속한 각 특성값들에 대해 MinMaxScaling을 수행함\n",
    "print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0))) \n",
    "print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\n",
    "print(\"per-feature minimum after scaling:\\n {}\".format(X_train_scaled.min(axis=0)))\n",
    "print(\"per-feature maximum after scaling:\\n {}\".format(X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 테스트 데이터도 변환해줌\n",
    "  - [주의] 테스트 데이터 변환시에 항상 훈련 데이터들의 통계치만을 사용\n",
    "  - 즉, 테스트 데이터에 대해 다음과 같은 공식을 통하여 변환\n",
    "$$\\dfrac{x_{test_{ij}} – x_{train_{min_j}}}{x_{train_{max_j}} – x_{train_{min_j}}}$$\n",
    "  - 위 식에서 i는 각 데이터 인덱스, j는 각 데이터들에 대한 특성 인덱스. 즉, min_j와 max_j는 동일한 j번째 특성들 전체에 대한 최소 및 최대값을 의미 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per-feature minimum after scaling:\n",
      "[ 0.0336031   0.0226581   0.03144219  0.01141039  0.14128374  0.04406704\n",
      "  0.          0.          0.1540404  -0.00615249 -0.00137796  0.00594501\n",
      "  0.00430665  0.00079567  0.03919502  0.0112206   0.          0.\n",
      " -0.03191387  0.00664013  0.02660975  0.05810235  0.02031974  0.00943767\n",
      "  0.1094235   0.02637792  0.          0.         -0.00023764 -0.00182032]\n",
      "per-feature maximum after scaling:\n",
      "[ 0.9578778   0.81501522  0.95577362  0.89353128  0.81132075  1.21958701\n",
      "  0.87956888  0.9333996   0.93232323  1.0371347   0.42669616  0.49765736\n",
      "  0.44117231  0.28371044  0.48703131  0.73863671  0.76717172  0.62928585\n",
      "  1.33685792  0.39057253  0.89612238  0.79317697  0.84859804  0.74488793\n",
      "  0.9154725   1.13188961  1.07008547  0.92371134  1.20532319  1.63068851]\n"
     ]
    }
   ],
   "source": [
    "# transform test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print test data properties after scaling\n",
    "print(\"per-feature minimum after scaling:\\n{}\".format(X_test_scaled.min(axis=0)))\n",
    "print(\"per-feature maximum after scaling:\\n{}\".format(X_test_scaled.max(axis=0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
